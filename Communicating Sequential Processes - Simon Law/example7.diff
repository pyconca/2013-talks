--- example6.py	2013-08-09 00:27:21.550064693 -0400
+++ example7.py	2013-08-09 00:27:31.226209552 -0400
@@ -1,6 +1,6 @@
 #!/usr/bin/env python3
 
-import hashlib
+import bs4
 import multiprocessing
 import queue
 import sys
@@ -8,6 +8,16 @@ import threading
 import urllib.request
 
 
+def pipeline(target, i):
+    o = queue.Queue()
+
+    for _ in range(multiprocessing.cpu_count()):
+        thread = threading.Thread(target=target, args=(i, o), daemon=True)
+        thread.start()
+
+    return o
+
+
 def urlget(i, o):
     while True:
         url = i.get()
@@ -17,23 +27,19 @@ def urlget(i, o):
         i.task_done()
 
 
-def hasher(i, o):
+def extract(i, o):
     while True:
         url, content = i.get()
-        o.put((url, hashlib.sha512(content).hexdigest()))
+        soup = bs4.BeautifulSoup(content)
+        links = [tag.attrs.get('src', '') for tag in soup.find_all('img')]
+        o.put((url, links))
         i.task_done()
 
 
-def hash_urls(urls):
-    i, q = queue.Queue(), queue.Queue()
-    for _ in range(multiprocessing.cpu_count()):
-        thread = threading.Thread(target=urlget, args=(i, q), daemon=True)
-        thread.start()
-
-    o = queue.Queue()
-    for _ in range(multiprocessing.cpu_count()):
-        thread = threading.Thread(target=hasher, args=(q, o), daemon=True)
-        thread.start()
+def extract_images(urls):
+    i = queue.Queue()
+    q = pipeline(urlget, i)
+    o = pipeline(extract, q)
 
     for url in urls:
         i.put(url)
@@ -43,8 +49,8 @@ def hash_urls(urls):
 
 
 if __name__ == '__main__':
-    contents = hash_urls(sys.argv[1:])
+    contents = extract_images(sys.argv[1:])
     for url, digest in contents:
         print("{}: {}".format(url, digest[:8]))
 
 
