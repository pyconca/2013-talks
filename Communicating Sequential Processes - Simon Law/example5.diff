--- example4.py	2013-08-09 00:27:09.609885972 -0400
+++ example5.py	2013-08-09 00:27:15.317971418 -0400
@@ -1,5 +1,6 @@
 #!/usr/bin/env python3
 
+import hashlib
 import multiprocessing
 import queue
 import re
@@ -10,16 +11,10 @@ import urllib.request
 
 def urlget(i, o):
     while True:
-        url, depth, maxdepth = i.get()
+        url = i.get()
         with urllib.request.urlopen(url) as response:
             content = response.read()
         o.put((url, content))
-
-        if depth < maxdepth:
-            match = re.search(r'href="(/\w.*?)"', content.decode('utf-8'))
-            if match:
-                i.put((url + match.group(1), depth + 1, maxdepth))
-
         i.task_done()
 
 
@@ -30,13 +25,33 @@ def download(urls):
         thread.start()
 
     for url in urls:
-        i.put((url, 0, 1))
+        i.put(url)
+
+    while i.unfinished_tasks > 0 or not o.empty():
+        yield o.get()
+
+
+def hasher(i, o):
+    while True:
+        url, content = i.get()
+        o.put((url, hashlib.sha512(content).hexdigest()))
+        i.task_done()
+
+
+def hash_urls(urls):
+    i, o = queue.Queue(), queue.Queue()
+    for _ in range(multiprocessing.cpu_count()):
+        thread = threading.Thread(target=hasher, args=(i, o), daemon=True)
+        thread.start()
+
+    for url, content in download(urls):
+        i.put((url, content))
 
     while i.unfinished_tasks > 0 or not o.empty():
         yield o.get()
 
 
 if __name__ == '__main__':
-    contents = download(sys.argv[1:])
-    for url, content in contents:
-        print("{}: {}".format(url, content[:50]))
+    contents = hash_urls(sys.argv[1:])
+    for url, digest in contents:
+        print("{}: {}".format(url, digest[:8]))
